{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ee250df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 PDF files to process...\n",
      "==================================================\n",
      "[1/8] Processing: Lia_1.pdf + Lib_1.pdf - ✓ Data extracted\n",
      "[2/8] Processing: Lia_2.pdf + Lib_2.pdf - ✓ Data extracted\n",
      "[3/8] Processing: Lia_3.pdf + Lib_3.pdf - ✓ Data extracted\n",
      "[4/8] Processing: Lia_4.pdf + Lib_4.pdf - ✓ Data extracted\n",
      "[5/8] Processing: Lia_5.pdf + Lib_5.pdf - ✓ Data extracted\n",
      "[6/8] Processing: Lia_6.pdf + Lib_6.pdf - ✓ Data extracted\n",
      "[7/8] Processing: Lia_7.pdf + Lib_7.pdf - ✓ Data extracted\n",
      "[8/8] Processing: Lia_8.pdf + Lib_8.pdf - ✓ Data extracted\n",
      "==================================================\n",
      "Processing completed! 8 records extracted\n",
      "Data saved to: 1_gemini.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "\n",
    "def get_configuration_constants():\n",
    "    return {\n",
    "        'GEMINI_API_KEY': \"AIzaSyCJvV-nlMzV36NRsGAmJCX_UICsEjAmYKI\",\n",
    "        'OPENAI_API_KEY': \"KEY\",\n",
    "        'MAX_CHARS': 30000,\n",
    "        'COLUMNS': [\n",
    "            \"title\", \"first_author\", \"current_1\", \"capacity_1\", \"current_2\", \"capacity_2\", \"electrolyte_volume\", \"li_thickness\"\n",
    "        ] + [f\"E_{i+1}\" for i in range(15)]\n",
    "    }\n",
    "\n",
    "\n",
    "def extract_text_from_pdf(file_path):\n",
    "    with open(file_path, \"rb\") as pdf_file:\n",
    "        reader = PdfReader(pdf_file)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "\n",
    "def find_si_file(main_filename, si_directory):\n",
    "    if not os.path.exists(si_directory):\n",
    "        return None\n",
    "    \n",
    "    main_basename = os.path.splitext(main_filename)[0]\n",
    "    si_files = [f for f in os.listdir(si_directory) if f.endswith(\".pdf\")]\n",
    "    \n",
    "    # Handle format like 'XXXa_Y' -> 'XXXb_Y' where XXX can be any name\n",
    "    if 'a_' in main_basename:\n",
    "        si_basename = main_basename.replace('a_', 'b_')\n",
    "        si_candidate = f\"{si_basename}.pdf\"\n",
    "        if si_candidate in si_files:\n",
    "            return si_candidate\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_combined_text_from_files(main_file_path, si_file_path=None):\n",
    "    combined_text = \"\"\n",
    "    \n",
    "    # Extract from main paper\n",
    "    try:\n",
    "        main_text = extract_text_from_pdf(main_file_path)\n",
    "        combined_text += main_text + \"\\n\\n\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading main paper: {str(e)}\")\n",
    "    \n",
    "    # Extract from SI if available\n",
    "    if si_file_path and os.path.exists(si_file_path):\n",
    "        try:\n",
    "            si_text = extract_text_from_pdf(si_file_path)\n",
    "            combined_text += si_text + \"\\n\\n\"\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading SI: {str(e)}\")\n",
    "    \n",
    "    return combined_text\n",
    "\n",
    "\n",
    "def create_extraction_prompt(text):\n",
    "    return f\"\"\"\n",
    "Please extract the following information from the lithium battery-related scientific paper.\n",
    "This text contains BOTH the main paper AND supporting information combined.\n",
    "Search through ALL the text to find the required information.\n",
    "\n",
    "If information is not found anywhere in the combined text, return \"N/A\".\n",
    "\n",
    "1. Paper title (title)\n",
    "2. First author name (first_author)\n",
    "3. Current density 1 (current_1) in mA/cm² for coulombic efficiency measurements.\n",
    "4. Capacity 1 (capacity_1) in mAh/cm² for coulombic efficiency measurements\n",
    "5. Current density 2 (current_2) in mA/cm² for coulombic efficiency measurements- second current density value if available.\n",
    "6. Capacity 2 (capacity_2) in mAh/cm² for coulombic efficiency measurements - second capacity value if available.\n",
    "7. Electrolyte amount (electrolyte_volume) in μL\n",
    "8. Thickness of lithium foil (li_thickness) in micrometers for coulombic efficiency measurements.\n",
    "9. Electrolyte formulations (electrolytes) - return as array\n",
    "\n",
    "RULES:\n",
    "- Search through the ENTIRE combined text (main paper + SI) for all information\n",
    "- For current_1, capacity_1, current_2, capacity_2, electrolyte_volume, li_thickness columns: return only numbers, no units\n",
    "- List ALL unique formulations\n",
    "- A unique formulation MUST contain at least one Li-salt and one solvent\n",
    "- Maximum 15 electrolyte formulations\n",
    "\n",
    "USE THE FOLLOWING FORMAT FOR ELECTROLYTE FORMULATIONS:\n",
    "- use Li-salt name first, then solvent(s)\n",
    "- use M for molarity (e.g., 1M, 2M)\n",
    "- use + to separate Li-salt and solvent\n",
    "- use + to separate additives\n",
    "- Use v/v for volume ratio\n",
    "- use wt% for weight percentage\n",
    "- Use mol/mol for molar ratio\n",
    "- Use () to indicate ratios\n",
    "\n",
    "Combined Text (Main Paper + Supporting Information):\n",
    "{text}\n",
    "\n",
    "Return in exact JSON format:\n",
    "{{  \n",
    "    \"title\": \"paper title\",\n",
    "    \"first_author\": \"first author name\",\n",
    "    \"current_1\": \"value\",\n",
    "    \"capacity_1\": \"value\",\n",
    "    \"current_2\": \"value\",\n",
    "    \"capacity_2\": \"value\",\n",
    "    \"electrolyte_volume\": \"value\",\n",
    "    \"li_thickness\": \"value\",\n",
    "    \"electrolytes\": [\"formulation 1\", \"formulation 2\", ...]\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def send_request(api_key, text, model_type):\n",
    "    if model_type == \"gemini\":\n",
    "        prompt = {\n",
    "            \"contents\": [{\n",
    "                \"parts\": [{\n",
    "                    \"text\": create_extraction_prompt(text)\n",
    "                }]\n",
    "            }],\n",
    "            \"generationConfig\": {\n",
    "                \"temperature\": 0.1,\n",
    "                \"topP\": 0.95,\n",
    "                \"topK\": 39,\n",
    "            },\n",
    "        }\n",
    "        api_url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={api_key}\"\n",
    "        headers = {'Content-Type': 'application/json'}\n",
    "        \n",
    "    elif model_type == \"openai\":\n",
    "        prompt = {\n",
    "            \"model\": \"gpt-4o-mini\",\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": create_extraction_prompt(text)\n",
    "                }\n",
    "            ],\n",
    "            \"temperature\": 0.1,\n",
    "            \"top_p\": 0.95\n",
    "        }\n",
    "        api_url = \"https://api.openai.com/v1/chat/completions\"\n",
    "        headers = {\n",
    "            'Content-Type': 'application/json',\n",
    "            'Authorization': f'Bearer {api_key}'\n",
    "        }\n",
    "    \n",
    "    response = requests.post(api_url, headers=headers, json=prompt)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"{model_type.upper()} API Error: {response.status_code} - {response.text}\")\n",
    "        return None\n",
    "    \n",
    "    return response\n",
    "\n",
    "\n",
    "def parse_response(response, model_type):\n",
    "    try:\n",
    "        response_json = response.json()\n",
    "        \n",
    "        if model_type == \"gemini\":\n",
    "            content = response_json[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
    "        elif model_type == \"openai\":\n",
    "            content = response_json[\"choices\"][0][\"message\"][\"content\"]\n",
    "        \n",
    "        json_match = re.search(r'\\{[\\s\\S]*\\}', content)\n",
    "        if not json_match:\n",
    "            print(f\"JSON not found in {model_type} response: {content}\")\n",
    "            return None\n",
    "            \n",
    "        result = json.loads(json_match.group())\n",
    "        return result\n",
    "        \n",
    "    except (KeyError, IndexError, json.JSONDecodeError) as e:\n",
    "        print(f\"{model_type} response parsing error: {str(e)}\")\n",
    "        print(f\"Full response: {response.text}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def format_extracted_info(result):\n",
    "    electrolytes = result.get(\"electrolytes\", [])\n",
    "    if not isinstance(electrolytes, list):\n",
    "        electrolytes = [electrolytes] if electrolytes != \"N/A\" else []\n",
    "    \n",
    "    extracted_info = {\n",
    "        \"title\": result.get(\"title\", \"N/A\"),\n",
    "        \"first_author\": result.get(\"first_author\", \"N/A\"),\n",
    "        \"current_1\": result.get(\"current_1\", \"N/A\"),\n",
    "        \"capacity_1\": result.get(\"capacity_1\", \"N/A\"),\n",
    "        \"current_2\": result.get(\"current_2\", \"N/A\"),\n",
    "        \"capacity_2\": result.get(\"capacity_2\", \"N/A\"),\n",
    "        \"electrolyte_volume\": result.get(\"electrolyte_volume\", \"N/A\"),\n",
    "        \"li_thickness\": result.get(\"li_thickness\", \"N/A\")\n",
    "    }\n",
    "    \n",
    "    for i in range(15):\n",
    "        key = f\"E_{i+1}\"\n",
    "        extracted_info[key] = electrolytes[i] if i < len(electrolytes) else \"N/A\"\n",
    "    \n",
    "    return extracted_info\n",
    "\n",
    "\n",
    "def extract_experiment_info(text, config):\n",
    "    use_model = config.get('USE_MODEL', 'gemini').lower()\n",
    "    \n",
    "    if len(text) > config['MAX_CHARS']:\n",
    "        text = text[:config['MAX_CHARS']] + \"... [TEXT TRUNCATED]\"\n",
    "    \n",
    "    if use_model == 'gemini':\n",
    "        api_key = config['GEMINI_API_KEY']\n",
    "    elif use_model == 'openai':\n",
    "        api_key = config['OPENAI_API_KEY']\n",
    "    else:\n",
    "        print(f\"Unknown model: {use_model}\")\n",
    "        return None\n",
    "    \n",
    "    response = send_request(api_key, text, use_model)\n",
    "    if response is None:\n",
    "        return None\n",
    "    \n",
    "    result = parse_response(response, use_model)\n",
    "    if result is None:\n",
    "        return None\n",
    "    \n",
    "    return format_extracted_info(result)\n",
    "\n",
    "\n",
    "def extract_info_from_pdf_in_directory(directory_path, si_directory_path, columns, config):\n",
    "    extracted_data = pd.DataFrame(columns=columns)\n",
    "    pdf_files = [f for f in os.listdir(directory_path) if f.endswith(\".pdf\")]\n",
    "    total_pdfs = len(pdf_files)\n",
    "    \n",
    "    print(f\"Found {total_pdfs} PDF files to process...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for idx, filename in enumerate(pdf_files, 1):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        si_filename = find_si_file(filename, si_directory_path)\n",
    "        si_file_path = os.path.join(si_directory_path, si_filename) if si_filename else None\n",
    "        \n",
    "        print(f\"[{idx}/{total_pdfs}] Processing: {filename}\", end=\"\")\n",
    "        if si_filename:\n",
    "            print(f\" + {si_filename}\", end=\"\")\n",
    "        \n",
    "        try:\n",
    "            text = extract_combined_text_from_files(file_path, si_file_path)\n",
    "            extracted_info = extract_experiment_info(text, config)\n",
    "            \n",
    "            if extracted_info:\n",
    "                extracted_data = pd.concat([\n",
    "                    extracted_data, \n",
    "                    pd.DataFrame([extracted_info])\n",
    "                ], ignore_index=True)\n",
    "                print(f\" - ✓ Data extracted\")\n",
    "            else:\n",
    "                print(f\" - No data extracted\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\" - ✗ Error: {str(e)}\")\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    return extracted_data\n",
    "\n",
    "\n",
    "def run_extraction(paper_name, si_paper_name, output_file, use_model):\n",
    "    config = get_configuration_constants()\n",
    "    config['USE_MODEL'] = use_model\n",
    "    \n",
    "    # Add model name to output filename\n",
    "    file_name, file_ext = os.path.splitext(output_file)\n",
    "    output_file_with_model = f\"{file_name}_{use_model}{file_ext}\"\n",
    "    \n",
    "    directory_path = os.path.join(os.getcwd(), paper_name)\n",
    "    si_directory_path = os.path.join(os.getcwd(), si_paper_name)\n",
    "    \n",
    "    if not os.path.exists(directory_path):\n",
    "        print(f\"Error: Main paper directory '{paper_name}' not found\")\n",
    "        return\n",
    "    \n",
    "    if not os.path.exists(si_directory_path):\n",
    "        print(f\"Warning: Supporting information directory '{si_paper_name}' not found\")\n",
    "    \n",
    "    data = extract_info_from_pdf_in_directory(\n",
    "        directory_path, \n",
    "        si_directory_path,\n",
    "        config['COLUMNS'], \n",
    "        config\n",
    "    )\n",
    "    \n",
    "    if not data.empty:\n",
    "        print(f\"Processing completed! {len(data)} records extracted\")\n",
    "        data.to_csv(output_file_with_model, index=False)\n",
    "        print(f\"Data saved to: {output_file_with_model}\")\n",
    "    else:\n",
    "        print(\"No data extracted\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    paper_name = \"paper\"\n",
    "    si_paper_name = \"paper_SI\"\n",
    "    output_file = \"1.csv\"\n",
    "    use_model = \"gemini\"  # Options: \"gemini\" or \"openai\"\n",
    "    \n",
    "    run_extraction(paper_name, si_paper_name, output_file, use_model)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c06bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Thinh = AIzaSyCJvV-nlMzV36NRsGAmJCX_UICsEjAmYKI\n",
    "Minh = AIzaSyDwmTavTSj9VwT9OQG37WWYVtyc2O_M3w8\n",
    "M = AIzaSyDb28g3Vagg-u_WQ39s2GGDuFO5pPmaM6Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720a215c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
