{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16 PDF files to process...\n",
      "Searching for keywords: Cu||Li, Li||Cu, Li-Cu, Cu-Li, Li || Cu, Cu || Li, coulombic efficiency, CE, coulombic efficiencies, CEs, conductivity, conductivities, viscosity, viscosities, aurbach\n",
      "Image quality filtering: Disabled\n",
      "==================================================\n",
      "[1/16] Processing: Lia_1.pdf - ✓ Extracted 2 images, 1 tables\n",
      "[2/16] Processing: Lia_2.pdf - ✓ Extracted 1 images, 0 tables\n",
      "[3/16] Processing: Lia_3.pdf - ✓ Extracted 1 images, 0 tables\n",
      "[4/16] Processing: Lia_4.pdf - ✓ Extracted 2 images, 0 tables\n",
      "[5/16] Processing: Lia_5.pdf - N/A\n",
      "[6/16] Processing: Lia_6.pdf - N/A\n",
      "[7/16] Processing: Lia_7.pdf - ✓ Extracted 2 images, 0 tables\n",
      "[8/16] Processing: Lia_8.pdf - ✓ Extracted 1 images, 0 tables\n",
      "[9/16] Processing: Lib_1.pdf - ✓ Extracted 3 images, 0 tables\n",
      "[10/16] Processing: Lib_2.pdf - ✓ Extracted 6 images, 1 tables\n",
      "[11/16] Processing: Lib_3.pdf - ✓ Extracted 1 images, 0 tables\n",
      "[12/16] Processing: Lib_4.pdf - N/A\n",
      "[13/16] Processing: Lib_5.pdf - ✓ Extracted 1 images, 0 tables\n",
      "[14/16] Processing: Lib_6.pdf - ✓ Extracted 1 images, 0 tables\n",
      "[15/16] Processing: Lib_7.pdf - N/A\n",
      "[16/16] Processing: Lib_8.pdf - N/A\n",
      "==================================================\n",
      "Processing completed! 21 images and 2 tables extracted\n",
      "Results saved to: extracted_images_report.csv\n",
      "Files saved to: c:\\Users\\dkbay\\Downloads\\code\\Project with Thinh\\LLM\\Paper_retrieval\\extracted_images\n"
     ]
    }
   ],
   "source": [
    "import fitz\n",
    "import re\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "\n",
    "def get_configuration_constants():\n",
    "    return {\n",
    "        'DEFAULT_KEYWORDS': [\n",
    "            \"Cu||Li\", \"Li||Cu\", \"Li-Cu\", \"Cu-Li\", \"Li || Cu\", \"Cu || Li\",\n",
    "            \"coulombic efficiency\", \"CE\", \"coulombic efficiencies\", \"CEs\",\n",
    "            \"conductivity\", \"conductivities\", \"viscosity\", \"viscosities\",\n",
    "            \"aurbach\"\n",
    "        ],\n",
    "        'ENABLE_IMAGE_FILTER': False,  # Set to True to enable image quality filtering\n",
    "        # Image quality filtering parameters\n",
    "        'MIN_WIDTH': 200,           # Minimum width in pixels\n",
    "        'MIN_HEIGHT': 150,          # Minimum height in pixels\n",
    "        'MIN_AREA': 50000,          # Minimum total area (width × height)\n",
    "        'MIN_FILE_SIZE': 10240,      # Minimum file size in bytes (10KB)\n",
    "        'MAX_FILE_SIZE': 3145728,   # Maximum file size in bytes (3MB)\n",
    "        'COMPLEXITY_THRESHOLD': 0.1  # Minimum image complexity (entropy-based)\n",
    "    }\n",
    "\n",
    "\n",
    "def find_keywords_in_text(text, keywords):\n",
    "    found_keywords = []\n",
    "    search_text = text.lower()\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        search_keyword = keyword.lower()\n",
    "        \n",
    "        if re.search(r'[^\\w\\s]', search_keyword):\n",
    "            if search_keyword in search_text:\n",
    "                found_keywords.append(keyword)\n",
    "        else:\n",
    "            pattern = r'\\b' + re.escape(search_keyword) + r'\\b'\n",
    "            if re.search(pattern, search_text):\n",
    "                found_keywords.append(keyword)\n",
    "    \n",
    "    return found_keywords\n",
    "\n",
    "\n",
    "def is_caption_text(text):\n",
    "    if re.search(r\"^(Figure|Fig\\.?|Supplementary Figure|Table|Supplementary Table)\\b\", text.strip(), re.IGNORECASE):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def calculate_image_entropy(image_array):\n",
    "    if len(image_array.shape) == 3:\n",
    "        gray = np.dot(image_array[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "    else:\n",
    "        gray = image_array\n",
    "    \n",
    "    hist, _ = np.histogram(gray.flatten(), bins=256, range=(0, 256))\n",
    "    hist = hist[hist > 0]\n",
    "    \n",
    "    if len(hist) == 0:\n",
    "        return 0\n",
    "    \n",
    "    prob = hist / hist.sum()\n",
    "    entropy = -np.sum(prob * np.log2(prob))\n",
    "    \n",
    "    return entropy / 8.0\n",
    "\n",
    "\n",
    "def check_image_quality(image_bytes, config):\n",
    "    try:\n",
    "        image = Image.open(io.BytesIO(image_bytes))\n",
    "        width, height = image.size\n",
    "        area = width * height\n",
    "        aspect_ratio = width / height if height > 0 else 0\n",
    "        file_size = len(image_bytes)\n",
    "        \n",
    "        rejection_reasons = []\n",
    "        \n",
    "        if file_size < config['MIN_FILE_SIZE']:\n",
    "            rejection_reasons.append(f\"file_size_too_small ({file_size} < {config['MIN_FILE_SIZE']})\")\n",
    "        elif file_size > config['MAX_FILE_SIZE']:\n",
    "            rejection_reasons.append(f\"file_size_too_large ({file_size} > {config['MAX_FILE_SIZE']})\")\n",
    "        \n",
    "        if width < config['MIN_WIDTH']:\n",
    "            rejection_reasons.append(f\"width_too_small ({width} < {config['MIN_WIDTH']})\")\n",
    "        if height < config['MIN_HEIGHT']:\n",
    "            rejection_reasons.append(f\"height_too_small ({height} < {config['MIN_HEIGHT']})\")\n",
    "        if area < config['MIN_AREA']:\n",
    "            rejection_reasons.append(f\"area_too_small ({area} < {config['MIN_AREA']})\")\n",
    "        \n",
    "        if width == height and width < 100:\n",
    "            rejection_reasons.append(\"likely_icon_or_logo\")\n",
    "        \n",
    "        if min(width, height) < 20:\n",
    "            rejection_reasons.append(\"likely_decorative_element\")\n",
    "        \n",
    "        try:\n",
    "            image_array = np.array(image)\n",
    "            entropy = calculate_image_entropy(image_array)\n",
    "            if entropy < config['COMPLEXITY_THRESHOLD']:\n",
    "                rejection_reasons.append(f\"low_complexity ({entropy:.3f} < {config['COMPLEXITY_THRESHOLD']})\")\n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "        is_quality = len(rejection_reasons) == 0\n",
    "        return is_quality, rejection_reasons\n",
    "        \n",
    "    except Exception as e:\n",
    "        return False, [f\"processing_error: {str(e)}\"]\n",
    "\n",
    "\n",
    "def find_table_caption(page, text_blocks):\n",
    "    table_captions = []\n",
    "    \n",
    "    for block in text_blocks:\n",
    "        if \"lines\" not in block:\n",
    "            continue\n",
    "            \n",
    "        block_text = \" \".join([span[\"text\"] for line in block[\"lines\"] for span in line[\"spans\"]]).strip()\n",
    "        \n",
    "        if re.search(r\"^(Table|Supplementary Table)\\b\", block_text.strip(), re.IGNORECASE):\n",
    "            block_rect = fitz.Rect(block[\"bbox\"])\n",
    "            table_captions.append({\n",
    "                'text': block_text,\n",
    "                'rect': block_rect\n",
    "            })\n",
    "    \n",
    "    return table_captions\n",
    "\n",
    "\n",
    "def extract_table_as_image(page, caption_info, output_dir, pdf_name, page_num, table_index):\n",
    "    config = get_configuration_constants()\n",
    "    \n",
    "    caption_rect = caption_info['rect']\n",
    "    \n",
    "    table_rect = fitz.Rect(\n",
    "        caption_rect.x0,\n",
    "        caption_rect.y1,\n",
    "        caption_rect.x1,\n",
    "        min(caption_rect.y1 + 300, page.rect.height)\n",
    "    )\n",
    "    \n",
    "    mat = fitz.Matrix(2, 2)\n",
    "    pix = page.get_pixmap(matrix=mat, clip=table_rect)\n",
    "    \n",
    "    img_data = pix.tobytes(\"png\")\n",
    "    \n",
    "    if config['ENABLE_IMAGE_FILTER']:\n",
    "        is_quality, _ = check_image_quality(img_data, config)\n",
    "        if not is_quality:\n",
    "            return None\n",
    "    \n",
    "    table_filename = f\"{pdf_name}_p{page_num+1}_table{table_index+1}.png\"\n",
    "    table_path = os.path.join(output_dir, table_filename)\n",
    "    \n",
    "    with open(table_path, \"wb\") as img_file:\n",
    "        img_file.write(img_data)\n",
    "    \n",
    "    return table_filename, table_path\n",
    "\n",
    "\n",
    "def find_image_caption(page, img_info, text_blocks):\n",
    "    img_rect = page.get_image_bbox(img_info)\n",
    "    best_caption = \"\"\n",
    "    best_distance = float('inf')\n",
    "    \n",
    "    for block in text_blocks:\n",
    "        if \"lines\" not in block:\n",
    "            continue\n",
    "            \n",
    "        block_rect = fitz.Rect(block[\"bbox\"])\n",
    "        block_text = \" \".join([span[\"text\"] for line in block[\"lines\"] for span in line[\"spans\"]]).strip()\n",
    "        \n",
    "        if not is_caption_text(block_text):\n",
    "            continue\n",
    "        \n",
    "        vertical_distance = abs(block_rect.y0 - img_rect.y1)\n",
    "        horizontal_overlap = min(img_rect.x1, block_rect.x1) - max(img_rect.x0, block_rect.x0)\n",
    "        \n",
    "        if horizontal_overlap > 0 and vertical_distance < 100:\n",
    "            if vertical_distance < best_distance:\n",
    "                best_caption = block_text\n",
    "                best_distance = vertical_distance\n",
    "    \n",
    "    return best_caption\n",
    "\n",
    "\n",
    "def extract_and_save_image(pdf, xref, page_num, output_dir, pdf_name, img_index):\n",
    "    config = get_configuration_constants()\n",
    "    \n",
    "    try:\n",
    "        base_image = pdf.extract_image(xref)\n",
    "        image_bytes = base_image[\"image\"]\n",
    "        image_ext = base_image[\"ext\"]\n",
    "    except Exception as e:\n",
    "        print(f\"    - Could not extract image on page {page_num+1}: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "    if config['ENABLE_IMAGE_FILTER']:\n",
    "        is_quality, _ = check_image_quality(image_bytes, config)\n",
    "        if not is_quality:\n",
    "            return None\n",
    "    \n",
    "    image_filename = f\"{pdf_name}_p{page_num+1}_fig{img_index+1}.{image_ext}\"\n",
    "    image_path = os.path.join(output_dir, image_filename)\n",
    "    \n",
    "    with open(image_path, \"wb\") as img_file:\n",
    "        img_file.write(image_bytes)\n",
    "    \n",
    "    return image_filename, image_path\n",
    "\n",
    "\n",
    "def process_single_pdf(pdf_path, keywords, output_dir):\n",
    "    pdf = fitz.open(pdf_path)\n",
    "    results = []\n",
    "    pdf_name = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "    \n",
    "    for page_num in range(len(pdf)):\n",
    "        page = pdf.load_page(page_num)\n",
    "        \n",
    "        images = page.get_images(full=True)\n",
    "        text_blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "        \n",
    "        for img_index, img_info in enumerate(images):\n",
    "            xref = img_info[0]\n",
    "            \n",
    "            caption = find_image_caption(page, img_info, text_blocks)\n",
    "            \n",
    "            if caption:\n",
    "                found_keywords = find_keywords_in_text(caption, keywords)\n",
    "                \n",
    "                if found_keywords:\n",
    "                    image_result = extract_and_save_image(pdf, xref, page_num, output_dir, pdf_name, img_index)\n",
    "                    if image_result:\n",
    "                        image_filename, image_path = image_result\n",
    "                        results.append({\n",
    "                            'type': 'image',\n",
    "                            'image_filename': image_filename,\n",
    "                            'image_path': image_path,\n",
    "                            'page': page_num + 1,\n",
    "                            'caption': caption,\n",
    "                            'keywords': found_keywords\n",
    "                        })\n",
    "        \n",
    "        table_captions = find_table_caption(page, text_blocks)\n",
    "        \n",
    "        for table_index, caption_info in enumerate(table_captions):\n",
    "            caption_text = caption_info['text']\n",
    "            found_keywords = find_keywords_in_text(caption_text, keywords)\n",
    "            \n",
    "            if found_keywords:\n",
    "                table_result = extract_table_as_image(page, caption_info, output_dir, pdf_name, page_num, table_index)\n",
    "                if table_result:\n",
    "                    table_filename, table_path = table_result\n",
    "                    results.append({\n",
    "                        'type': 'table',\n",
    "                        'image_filename': table_filename,\n",
    "                        'image_path': table_path,\n",
    "                        'page': page_num + 1,\n",
    "                        'caption': caption_text,\n",
    "                        'keywords': found_keywords\n",
    "                    })\n",
    "    \n",
    "    pdf.close()\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_all_pdf_files(paper_folder, si_folder):\n",
    "    all_files = []\n",
    "    \n",
    "    if os.path.exists(paper_folder):\n",
    "        paper_files = [f for f in os.listdir(paper_folder) if f.lower().endswith('.pdf')]\n",
    "        for f in paper_files:\n",
    "            all_files.append((os.path.join(paper_folder, f), f))\n",
    "    \n",
    "    if os.path.exists(si_folder):\n",
    "        si_files = [f for f in os.listdir(si_folder) if f.lower().endswith('.pdf')]\n",
    "        for f in si_files:\n",
    "            all_files.append((os.path.join(si_folder, f), f))\n",
    "    \n",
    "    return all_files\n",
    "\n",
    "\n",
    "def write_results_to_csv(output_csv, all_results):\n",
    "    fieldnames = ['pdf_file', 'type', 'image_file', 'page', 'caption', 'keywords']\n",
    "    \n",
    "    with open(output_csv, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        \n",
    "        for result in all_results:\n",
    "            writer.writerow({\n",
    "                'pdf_file': result['pdf_file'],\n",
    "                'type': result['type'],\n",
    "                'image_file': result['image_filename'],\n",
    "                'page': result['page'],\n",
    "                'caption': result['caption'],\n",
    "                'keywords': \"; \".join(result['keywords'])\n",
    "            })\n",
    "\n",
    "\n",
    "def process_pdf_folders(paper_folder, si_folder, output_csv, extracted_images_folder, keywords=None):\n",
    "    config = get_configuration_constants()\n",
    "    \n",
    "    if keywords is None:\n",
    "        keywords = config['DEFAULT_KEYWORDS']\n",
    "    \n",
    "    output_dir = os.path.join(os.getcwd(), extracted_images_folder)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    all_results = []\n",
    "    all_files = get_all_pdf_files(paper_folder, si_folder)\n",
    "    total_files = len(all_files)\n",
    "    \n",
    "    print(f\"Found {total_files} PDF files to process...\")\n",
    "    print(f\"Searching for keywords: {', '.join(keywords)}\")\n",
    "    print(f\"Image quality filtering: {'Enabled' if config['ENABLE_IMAGE_FILTER'] else 'Disabled'}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for idx, (file_path, filename) in enumerate(all_files, 1):\n",
    "        print(f\"[{idx}/{total_files}] Processing: {filename}\", end=\"\")\n",
    "        \n",
    "        try:\n",
    "            pdf_results = process_single_pdf(file_path, keywords, output_dir)\n",
    "            \n",
    "            for result in pdf_results:\n",
    "                result['pdf_file'] = filename\n",
    "                all_results.append(result)\n",
    "            \n",
    "            images_count = len([r for r in pdf_results if r['type'] == 'image'])\n",
    "            tables_count = len([r for r in pdf_results if r['type'] == 'table'])\n",
    "            \n",
    "            if pdf_results:\n",
    "                print(f\" - ✓ Extracted {images_count} images, {tables_count} tables\")\n",
    "            else:\n",
    "                print(f\" - N/A\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\" - ✗ Error: {str(e)}\")\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    write_results_to_csv(output_csv, all_results)\n",
    "    \n",
    "    total_images = len([r for r in all_results if r['type'] == 'image'])\n",
    "    total_tables = len([r for r in all_results if r['type'] == 'table'])\n",
    "    \n",
    "    print(f\"Processing completed! {total_images} images and {total_tables} tables extracted\")\n",
    "    print(f\"Results saved to: {output_csv}\")\n",
    "    print(f\"Files saved to: {output_dir}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    paper_folder = os.path.join(os.getcwd(), \"paper\")\n",
    "    si_folder = os.path.join(os.getcwd(), \"paper_SI\")\n",
    "    OUTPUT_CSV = \"extracted_images_report.csv\"\n",
    "    EXTRACTED_IMAGES_FOLDER = \"extracted_images\"\n",
    "    \n",
    "    config = get_configuration_constants()\n",
    "    \n",
    "    process_pdf_folders(\n",
    "        paper_folder=paper_folder,\n",
    "        si_folder=si_folder,\n",
    "        output_csv=OUTPUT_CSV,\n",
    "        extracted_images_folder=EXTRACTED_IMAGES_FOLDER,\n",
    "        keywords=config['DEFAULT_KEYWORDS']\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
